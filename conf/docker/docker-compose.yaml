x-default-health-check: &default-health-check
  interval: ${HEALTH_CHECK_INTERVAL}
  timeout: ${HEALTH_CHECK_TIMEOUT}
  retries: ${HEALTH_CHECK_RETIES}
  start_period: ${HEALTH_CHECK_START_PERIOD}

networks:
  mc-infra-connector-network:
  mc-infra-manager-network:
  mc-iam-manager-network:
  mc-cost-optimizer-network:
  mc-application-manager-network:
  mc-workflow-manager-network:
  mc-data-manager-network:
  mc-observability-network:
  mc-web-console-network:


services:
  ##### MC-INFRA-CONNECTOR #########################################################################################################################

  mc-infra-connector:
    image: cloudbaristaorg/cb-spider:0.11.1
    pull_policy: if_not_present
    container_name: mc-infra-connector
    platform: linux/amd64
    networks:
      - mc-infra-connector-network
      - mc-web-console-network
    ports:
      - target: 1024
        published: 1024
        protocol: tcp
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./conf/mc-infra-connector/:/root/go/src/github.com/cloud-barista/cb-spider/conf/:ro
      - ./container-volume/mc-infra-connector/meta_db/:/root/go/src/github.com/cloud-barista/cb-spider/meta_db/
      - ./container-volume/mc-infra-connector/log/:/root/go/src/github.com/cloud-barista/cb-spider/log/
    environment:
      - PLUGIN_SW=OFF
      - SERVER_ADDRESS=0.0.0.0:1024
      # if you leave these values empty, REST Auth will be disabled.
      # - API_USERNAME=
      # - API_PASSWORD=
      - SPIDER_LOG_LEVEL=error
      - SPIDER_HISCALL_LOG_LEVEL=error
      - ID_TRANSFORM_MODE=OFF
    healthcheck:
      # for CB-Spider
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:1024/spider/readyz" ]
      <<: *default-health-check

  ##### MC-INFRA-MANAGER #########################################################################################################################

  mc-infra-manager:
    image: cloudbaristaorg/cb-tumblebug:0.11.1
    container_name: mc-infra-manager
    pull_policy: if_not_present
    platform: linux/amd64
    networks:
      - mc-infra-connector-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 1323
        published: 1323
        protocol: tcp
    depends_on:
      mc-infra-manager-etcd:
        condition: service_started
      mc-infra-connector:
        condition: service_started
      mc-infra-manager-postgres:
        condition: service_healthy
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./conf/mc-infra-manager/:/app/conf/:ro
      - ./container-volume/mc-infra-manager/meta_db/:/app/meta_db/
      - ./container-volume/mc-infra-manager/log/:/app/log/
    environment:
      # - TB_ROOT_PATH=/app
      - TB_SPIDER_REST_URL=http://mc-infra-connector:1024/spider
      - TB_ETCD_ENDPOINTS=http://mc-infra-manager-etcd:2379
      - TB_TERRARIUM_REST_URL=http://mc-terrarium:8055/terrarium
      - TB_IAM_MANAGER_REST_URL=http://mc-iam-manager:5000
      # - TB_ETCD_AUTH_ENABLED=true
      # - TB_ETCD_USERNAME=default
      # - TB_ETCD_PASSWORD=default
      - TB_POSTGRES_ENDPOINT=mc-infra-manager-postgres:5432
      - TB_POSTGRES_DATABASE=cb_tumblebug
      - TB_POSTGRES_USER=cb_tumblebug
      - TB_POSTGRES_PASSWORD=cb_tumblebug
      # - TB_ALLOW_ORIGINS=*
      # - TB_AUTH_ENABLED=true
      # - TB_API_USERNAME=default
      # - TB_API_PASSWORD=default
      # - TB_AUTOCONTROL_DURATION_MS=10000
      # - TB_SELF_ENDPOINT=localhost:1323
      # - TB_DRAGONFLY_REST_URL=http://cb-dragonfly:9090/dragonfly
      # - TB_DEFAULT_NAMESPACE=ns01
      # - TB_DEFAULT_CREDENTIALHOLDER=admin
      # - TB_LOGFILE_PATH=/app/log/tumblebug.log
      # - TB_LOGFILE_MAXSIZE=10
      # - TB_LOGFILE_MAXBACKUPS=3
      # - TB_LOGFILE_MAXAGE=30
      # - TB_LOGFILE_COMPRESS=false
      # - TB_LOGLEVEL=debug
      # - TB_LOGWRITER=both
      # - TB_NODE_ENV=development
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:1323/tumblebug/readyz" ]
      <<: *default-health-check

  mc-infra-manager-etcd:
    image: gcr.io/etcd-development/etcd:v3.5.14
    container_name: mc-infra-manager-etcd
    networks:
      - mc-infra-manager-network
    ports:
      - target: 2379
        published: 2379
        protocol: tcp
      - target: 2380
        published: 2380
        protocol: tcp
    volumes:
      - ./container-volume/mc-infra-manager/etcd/data:/etcd-data
    entrypoint: /usr/local/bin/etcd
    command:
      - --name
      - s1
      - --data-dir
      - /etcd-data
      - --listen-client-urls
      - http://0.0.0.0:2379
      - --advertise-client-urls
      - http://0.0.0.0:2379
      - --listen-peer-urls
      - http://0.0.0.0:2380
      - --initial-advertise-peer-urls
      - http://0.0.0.0:2380
      - --initial-cluster
      - s1=http://0.0.0.0:2380
      - --initial-cluster-token
      - tkn
      - --initial-cluster-state
      - new
      - --log-level
      - info
      - --logger
      - zap
      - --log-outputs
      - stderr
      - --auth-token
      - simple
    healthcheck:
      test: [ "CMD", "etcdctl", "endpoint", "health", "--endpoints=http://localhost:2379" ]
      <<: *default-health-check

  # mc-infra-manager PostgreSQL
  # This is used for storing CB-Tumblebug Spec and Image.
  mc-infra-manager-postgres:
    image: postgres:16-alpine
    container_name: mc-infra-manager-postgres
    restart: always
    networks:
      - mc-infra-manager-network
      # # Enable external network for outbound access (not ideal for security)
      # - external_network
    ports:
      - 6432:5432
    volumes:
      - ./container-volume/mc-infra-manager/meta_db/postgres:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=cb_tumblebug
      - POSTGRES_PASSWORD=cb_tumblebug
      - POSTGRES_DB=cb_tumblebug
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U cb_tumblebug" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  ##### MC-IAM-MANAGER #########################################################################################################################

  mc-iam-manager:
    container_name: mc-iam-manager
    image: cloudbaristaorg/mc-iam-manager:edge
    pull_policy: if_not_present
    platform: linux/amd64
    restart: unless-stopped
    networks:
      - mc-iam-manager-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 5000
        published: 5000
        protocol: tcp
    depends_on:
      - mc-iam-manager-db
      - mc-iam-manager-kc
    environment:
      DATABASE_URL: postgres://${MC_IAM_MANAGER_DATABASE_USER}:${MC_IAM_MANAGER_DATABASE_PASSWORD}@mc-iam-manager-db:5432/${MC_IAM_MANAGER_DATABASE_NAME}
      PORT: 5000
    env_file:
      - ./conf/mc-iam-manager/.env
    volumes:
      - ./tool/mcc:/app/tool/mcc
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:${MC_IAM_MANAGER_PORT}/readyz" ]
      <<: *default-health-check

  mc-iam-manager-db:
    container_name: mc-iam-manager-db
    image: postgres:14-alpine
    pull_policy: if_not_present
    platform: linux/amd64
    restart: unless-stopped
    networks:
      - mc-iam-manager-network
    ports:
      - target: 5432
        published: 5432
        protocol: tcp
    volumes:
      - ./container-volume/mc-iam-manager/postgres/postgres_data:/var/lib/postgresql/data
      - ./conf/mc-iam-manager/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro
    environment:
      POSTGRES_DB: ${MC_IAM_MANAGER_DATABASE_NAME}
      POSTGRES_USER: ${MC_IAM_MANAGER_DATABASE_USER}
      POSTGRES_PASSWORD: ${MC_IAM_MANAGER_DATABASE_PASSWORD}
    env_file:
      - ./conf/mc-iam-manager/.env
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${MC_IAM_MANAGER_DATABASE_USER} -d ${MC_IAM_MANAGER_DATABASE_NAME}" ]
      <<: *default-health-check
    command: >
      sh -c "chown -R 70:70 /var/lib/postgresql/data &&
            exec docker-entrypoint.sh postgres"

  mc-iam-manager-kc:
    container_name: mc-iam-manager-kc
    image: quay.io/keycloak/keycloak:24.0.1
    restart: unless-stopped
    networks:
      - mc-iam-manager-network
    ports:
      - target: 8080
        published: 8080
        protocol: tcp
    command:
      - start-dev
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://mc-iam-manager-db:5432/${MC_IAM_MANAGER_DATABASE_NAME}
      KC_DB_USERNAME: ${MC_IAM_MANAGER_DATABASE_USER}
      KC_DB_PASSWORD: ${MC_IAM_MANAGER_DATABASE_PASSWORD}
      KC_HOSTNAME_PORT: 8080
      KC_HOSTNAME_STRICT: "false"
      KC_HOSTNAME_STRICT_HTTPS: "false"
      KC_HOSTNAME: ${MC_IAM_MANAGER_KEYCLOAK_HOST}
      KEYCLOAK_ADMIN: ${MC_IAM_MANAGER_KEYCLOAK_ADMIN:-admin}
      KEYCLOAK_ADMIN_PASSWORD: ${MC_IAM_MANAGER_KEYCLOAK_ADMIN_PASSWORD:-admin_password}
      KC_HTTP_ENABLED: "true"
      KC_PROXY: edge
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./container-volume/mc-iam-manager/keycloak/data/:/opt/keycloak/data/
    env_file:
      - ./conf/mc-iam-manager/.env
    depends_on:
      - mc-iam-manager-db
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:8080/" ]
      # test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:8080/health/ready" ]
      <<: *default-health-check

  mc-iam-manager-nginx:
    image: nginx:1.25-alpine
    container_name: mc-iam-manager-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    environment:
      - DOMAIN_NAME=${MC_IAM_MANAGER_KEYCLOAK_DOMAIN:-localhost}
    volumes:
      - ./conf/mc-iam-manager/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./container-volume/certs:/etc/nginx/certs:ro
      - ./container-volume/certbot/www:/var/www/certbot:ro
    depends_on:
      - mc-iam-manager-kc
    networks:
      - mc-iam-manager-network


  mc-iam-manager-post-initial:
    image: ubuntu:22.04
    container_name: mc-iam-manager-post-initial
    # restart: unless-stopped
    networks:
      - mc-iam-manager-network
    depends_on:
      mc-iam-manager:
        condition: service_healthy
      mc-iam-manager-db:
        condition: service_healthy
      mc-iam-manager-kc:
        condition: service_healthy
    env_file:
      - ./conf/mc-iam-manager/.env
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./conf/mc-iam-manager/:/app/mc-iam-manager/
    working_dir: /app/mc-iam-manager
    command: bash /app/mc-iam-manager/docker-post-init.sh


  ##### MC-COST-OPTIMIZER #########################################################################################################################

  mc-cost-optimizer-fe:
    restart: on-failure
    container_name: mc-cost-optimizer-fe
    image: cloudbaristaorg/mc-costopti-ui:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 80
        published: 7780
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-be
    volumes:
      - ./tool/mcc:/app/tool/mcc
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:80" ]
      <<: *default-health-check

  mc-cost-optimizer-be:
    restart: on-failure
    container_name: mc-cost-optimizer-be
    image: cloudbaristaorg/mc-costopti-api:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 9090
        published: 9090
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.cost.optimize.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.cost.optimize.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.cost.optimize.password: ${CO_MYSQL_PASSWORD}
      tumblebug.url: http://mc-infra-manager:1323/tumblebug
      tumblebug.username: default
      tumblebug.password: default
      costopti.alarmservice.url: ${CO_ALARM_URL}
      costopti.assetcollector.url: ${CO_COST_ASSET_COLLECTOR_URL}
      costopti.costcollector.url: ${CO_COST_COLLECTOR_URL}
      costopti.costprocessor.url: ${CO_COST_PROCESSOR_URL}
      costopti.costselector.url: ${CO_COST_SELECTOR_URL}
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:9090/api/costopti/be/readyz" ]
      <<: *default-health-check

  mc-cost-optimizer-cost-collector:
    restart: on-failure
    container_name: mc-cost-optimizer-cost-collector
    image: cloudbaristaorg/mc-costopti-costcollector:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 8081
        published: 8881
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.batch.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.batch.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.batch.password: ${CO_MYSQL_PASSWORD}
      unusedBatchCronSchedule: ${CO_COST_COLLECT_UNUSED_CRON_SCHEDULE}
      curBatchCronSchedule: ${CO_COST_COLLECT_CUR_CRON_SCHEDULE}
      aws.data.export.name: ${CO_AWS_CUR_EXPORT_NAME}
      aws.data.export.path.prefix: ${CO_AWS_CUR_EXPORT_PATH_PREFIX}
      AWS_ACCESS_KEY_ID: ${CO_AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${CO_AWS_SECRET_ACCESS_KEY}

  mc-cost-optimizer-cost-processor:
    restart: on-failure
    container_name: mc-cost-optimizer-cost-processor
    image: cloudbaristaorg/mc-costopti-costprocessor:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 8082
        published: 18082
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.batch.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.batch.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.batch.password: ${CO_MYSQL_PASSWORD}
      unusedProcessCronSchedule: ${CO_COST_PROCESS_UNUSED_CRON_SCHEDULE}
      abnormalProcessCronSchedule: ${CO_COST_PROCESS_ABNORMAL_CRON_SCHEDULE}
      cost.selector.url: ${CO_COST_SELECTOR_URL}
      opti.alarm.url: ${CO_ALARM_URL}

  mc-cost-optimizer-cost-selector:
    restart: on-failure
    container_name: mc-cost-optimizer-cost-selector
    image: cloudbaristaorg/mc-costopti-costselector:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 8083
        published: 8083
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.cost.optimize.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.cost.optimize.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.cost.optimize.password: ${CO_MYSQL_PASSWORD}
      opti.alarm.url: ${CO_ALARM_URL}

  mc-cost-optimizer-alarm-service:
    restart: on-failure
    container_name: mc-cost-optimizer-alarm-service
    image: cloudbaristaorg/mc-costopti-alarm:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 9000
        published: 9000
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.slack.jdbc-url: ${CO_SLACK_DB_URL}
      spring.datasource.hikari.slack.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.slack.password: ${CO_MYSQL_PASSWORD}
      spring.datasource.hikari.mailing.jdbc-url: ${CO_MAIL_DB_URL}
      spring.datasource.hikari.mailing.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.mailing.password: ${CO_MYSQL_PASSWORD}
      spring.datasource.hikari.history.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.history.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.history.password: ${CO_MYSQL_PASSWORD}

  mc-cost-optimizer-asset-collector:
    restart: on-failure
    container_name: mc-cost-optimizer-asset-collector
    image: cloudbaristaorg/mc-costopti-assetcollector:0.4.0
    networks:
      - mc-cost-optimizer-network
      - mc-observability-network
      - mc-infra-manager-network
      - mc-web-console-network
    ports:
      - target: 8091
        published: 8091
        protocol: tcp
    depends_on:
      - mc-cost-optimizer-db
    volumes:
      - ./tool/mcc:/app/tool/mcc
    environment:
      spring.datasource.hikari.batch.jdbc-url: ${CO_COST_DB_URL}
      spring.datasource.hikari.batch.username: ${CO_MYSQL_USER}
      spring.datasource.hikari.batch.password: ${CO_MYSQL_PASSWORD}
      costopti.be.url: ${CO_API_URL}
      asset.collect.url: ${CO_ASSET_MONITORING_SERVER}
      assetCollectBatchCronSchedule: ${CO_ASSET_COLLECT_BATCH_CRON_SCHEDULE}

  mc-cost-optimizer-db:
    image: mariadb:latest
    container_name: mc-cost-optimizer-db
    environment:
      - ALLOW_EMPTY_PASSWORD=no
      - MYSQL_ROOT_PASSWORD=${CO_MYSQL_ROOT_PASSWORD}
      - MYSQL_USER=${CO_MYSQL_USER}
      - MYSQL_PASSWORD=${CO_MYSQL_PASSWORD}
    command:
      - --skip-character-set-client-handshake
    ports:
      - target: 3306
        published: 3307
        protocol: tcp
    volumes:
      - ./conf/mc-cost-optimizer/init/:/docker-entrypoint-initdb.d
      - ./container-volume/mc-cost-optimizer/mysql/:/var/lib/mysql/
    networks:
      - mc-cost-optimizer-network
      - mc-web-console-network
    healthcheck:
      test: [ "CMD", "healthcheck.sh", "--su-mysql", "--connect", "--innodb_initialized" ]
      <<: *default-health-check

  ##### MC-APPLICATION-MANAGER #########################################################################################################################

  mc-application-manager-jenkins:
    image: bitnami/jenkins:2.462.3
    user: root
    container_name: mc-application-manager-jenkins
    platform: linux/amd64
    networks:
      - mc-application-manager-network
      - mc-web-console-network
    ports:
      - target: 8080
        published: 9800
        protocol: tcp
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /usr/bin/docker:/usr/bin/docker
      - ./container-volume/mc-application-manager/jenkins/:/bitnami/jenkins/home:rw
    environment:
      JENKINS_USERNAME: admin
      JENKINS_PASSWORD: 123456 # Please CHANGE ME
      JENKINS_PLUGINS: >-
        workflow-api, swarm, authorize-project, antisamy-markup-formatter, pipeline-github-lib, pipeline-rest-api, git, github-branch-source, gradle, pipeline-model-definition, pipeline-build-step, workflow-aggregator, matrix-project, email-ext, durable-task, checks-api, build-timeout, timestamper, ws-cleanup, ssh-slaves, ssh-agent, publish-over-ssh
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/login" ]
      interval: 1m
      timeout: 5s
      retries: 3
      start_period: 10s

  mc-application-manager-sonatype-nexus:
    image: sonatype/nexus3:latest
    container_name: mc-application-manager-sonatype-nexus
    platform: linux/amd64
    networks:
      - mc-application-manager-network
      - mc-web-console-network
    ports:
      - target: 8081
        published: 8081
        protocol: tcp
      - target: 5000
        published: 5500
        protocol: tcp
    volumes:
      - ./container-volume/mc-application-manager/nexus/:/nexus-data:rw
    environment:
      NEXUS_SECURITY_RANDOMPASSWORD: 'false'
      NEXUS_SECURITY_INITIAL_PASSWORD: 123456 # Please CHANGE ME
    user: root
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081" ]
      <<: *default-health-check

  mc-application-manager:
    image: cloudbaristaorg/mc-application-manager:0.4.0
    container_name: mc-application-manager
    networks:
      - mc-application-manager-network
      - mc-web-console-network
    ports:
      - target: 18084
        published: 18084
        protocol: tcp
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./container-volume/mc-application-manager/nexus/:/nexus-data:rw
    user: root
    environment:
      - DDL_AUTO=update
      - DB_USER=application # Please CHANGE ME
      - DB_PASS=application!23 # Please CHANGE ME
      - SQL_DATA_INIT=never
      - TUMBLEBUG_URL=mc-infra-manager
      - TUMBLEBUG_PORT=1323
      - TUMBLEBUG_ID=default
      - TUMBLEBUG_PASSWORD=default
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:18084/readyz" ]
      <<: *default-health-check

  ##### MC-WORKFLOW-MANAGER #########################################################################################################################

  mc-workflow-manager-jenkins:
    image: bitnami/jenkins:2.462.3
    container_name: mc-workflow-manager-jenkins
    platform: linux/amd64
    networks:
      - mc-workflow-manager-network
    ports:
      - target: 8080
        published: 9880
        protocol: tcp
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /usr/bin/docker:/usr/bin/docker
      - ./container-volume/mc-workflow-manager/jenkins/:/bitnami/jenkins/home:rw
    environment:
      JENKINS_USERNAME: admin
      JENKINS_PASSWORD: 123456 # Please CHANGE ME
      JENKINS_PLUGINS: >-
        workflow-api, swarm, authorize-project, antisamy-markup-formatter, pipeline-github-lib, pipeline-rest-api, git, github-branch-source, gradle, pipeline-model-definition, pipeline-build-step, workflow-aggregator, matrix-project, email-ext, durable-task, checks-api, build-timeout, timestamper, ws-cleanup, ssh-slaves, ssh-agent, publish-over-ssh
    user: root
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/login" ]
      <<: *default-health-check

  mc-workflow-manager:
    image: cloudbaristaorg/mc-workflow-manager:0.4.0
    container_name: mc-workflow-manager
    platform: linux/amd64
    networks:
      - mc-workflow-manager-network
      - mc-web-console-network
    ports:
      - target: 18083
        published: 18083
        protocol: tcp
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./conf/mc-workflow-manager/document/:/document/
    environment:
      - DB_INIT_YN=create
      - DB_ID=workflow # Please CHANGE ME
      - DB_PW=workflow!23 # Please CHANGE ME
      - SQL_DATA_INIT=always
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:18083/readyz" ]
      <<: *default-health-check

  ##### MC-DATA-MANAGER #########################################################################################################################

  mc-data-manager-init-volumes:
    image: busybox:stable
    container_name: mc-data-manager-init-volumes
    command: [ "sh", "-c", "chown -R ${UID:-0}:${GID:-0} /app/data" ]
    volumes:
      - ./conf/mc-data-manager/data:/app/data/
    user: root
    env_file:
      - ./conf/mc-data-manager/.env
    init: true
    networks:
      - mc-data-manager-network

  mc-data-manager:
    image: cloudbaristaorg/mc-data-manager:0.4.0
    container_name: mc-data-manager
    depends_on:
      - mc-data-manager-init-volumes
    tty: true
    ports:
      - target: 3300
        published: 3300
        protocol: tcp
    restart: on-failure
    user: root
    volumes:
      - ./conf/mc-data-manager/data:/app/data/
      - ./conf/mc-data-manager/scripts:/app/scripts/
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - ./conf/mc-data-manager/.env
    networks:
      - mc-data-manager-network
      - mc-web-console-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3300/readyZ" ]
      <<: *default-health-check

  ##### MC-WEB-CONSOLE #########################################################################################################################

  mc-web-console-db:
    image: postgres:14-alpine
    container_name: mc-web-console-db
    restart: unless-stopped
    volumes:
      - ./container-volume/mc-web-console/postgres/postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: ${CONSOLE_POSTGRES_DB}
      POSTGRES_USER: ${CONSOLE_POSTGRES_USER}
      POSTGRES_PASSWORD: ${CONSOLE_POSTGRES_PASSWORD}
    networks:
      - mc-web-console-network
    pull_policy: if_not_present
    platform: linux/amd64
    ports:
      - target: 5432
        published: 15432
        protocol: tcp
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      <<: *default-health-check
    command: >
      sh -c "chown -R 70:70 /var/lib/postgresql/data &&
            exec docker-entrypoint.sh postgres"

  mc-web-console-api:
    # image: sehyeong0108/mc-web-console-api:20241101
    image: cloudbaristaorg/mc-web-console-api:0.4.1
    container_name: mc-web-console-api
    restart: unless-stopped
    depends_on:
      - mc-web-console-db
      - mc-infra-connector
      - mc-infra-manager
      - mc-iam-manager
      - mc-observability-manager
      - mc-workflow-manager
      - mc-data-manager
      - mc-application-manager
      - mc-cost-optimizer-be
    ports:
      - target: 3000
        published: 3000
        protocol: tcp
    networks:
      - mc-web-console-network
      - mc-iam-manager-network
    environment:
      GO_ENV: development
      GODEBUG: netdns=go
      API_ADDR: "0.0.0.0"
      API_PORT: "3000"
      DATABASE_URL: postgres://${CONSOLE_POSTGRES_USER}:${CONSOLE_POSTGRES_PASSWORD}@mc-web-console-db:5432/${CONSOLE_POSTGRES_DB}
      MCIAM_USE: "true"
      MCIAM_TICKET_USE: "false"
      IFRAME_TARGET_IS_HOST: "true"
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./conf/mc-web-console/api/conf/:/conf/
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:3000/readyz" ]
      <<: *default-health-check

  mc-web-console-front:
    # image: sehyeong0108/mc-web-console-front:20241101
    image: cloudbaristaorg/mc-web-console-front:0.4.1
    container_name: mc-web-console-front
    restart: unless-stopped
    depends_on:
      - mc-web-console-api
    networks:
      - mc-web-console-network
      - mc-iam-manager-network
    ports:
      - target: 3001
        published: 3001
        protocol: tcp
    environment:
      API_ADDR: mc-web-console-api
      API_PORT: 3000
      FRONT_ADDR: 0.0.0.0
      FRONT_PORT: 3001
    volumes:
      - ./tool/mcc:/app/tool/mcc
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:3001" ]
      <<: *default-health-check

  ##### MC-OBSERVABILITY #########################################################################################################################

  mc-observability-manager:
    image: cloudbaristaorg/mc-observability:0.4.0
    container_name: mc-observability-manager
    ports:
      - target: 18080
        published: 18080
        protocol: tcp
      - target: 18081
        published: 18081
        protocol: tcp
    networks:
      - mc-observability-network
      - mc-cost-optimizer-network
      - mc-infra-manager-network
      - mc-infra-connector-network
      - mc-web-console-network
    environment:
      - TARGET_ID=mc-o11y
      - TUMBLEBUG_URL=http://mc-infra-manager:1323
      - TUMBLEBUG_ID=default
      - TUMBLEBUG_PW=default
      - SPIDER_URL=http://mc-infra-connector:1024
      - DATABASE_HOST=mc-observability-maria
      - INSIGHT_URL=http://mc-observability-insight:9001
      - SPIDER_MONITORING_INFLUXDB_URL=http://mc-observability-influx:8086
      - AGENT_MANAGER_IP=http://mc-observability-manager:18080
    env_file:
      - ./conf/mc-observability/manager/.env
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - /var/log/syslog:/var/log/syslog:ro
      - ./conf/mc-observability/manager/manager-conf/c_1.conf:/etc/mc-observability-agent/conf/c_1.conf:ro
      - ./conf/mc-observability/manager/manager-conf/c_2.conf:/etc/mc-observability-agent/conf/c_2.conf:ro
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:18080/api/o11y/readyz" ]
      <<: *default-health-check

  mc-observability-maria:
    image: mariadb:10.7.6
    container_name: mc-observability-maria
    ports:
      - target: 3306
        published: 3306
        protocol: tcp
    volumes:
      - ./conf/mc-observability/mariadb/maria_init.sql:/docker-entrypoint-initdb.d/maria_init.sql
      - ./conf/mc-observability/mariadb/99-max-connections.cnf:/etc/mysql/mariadb.conf.d/99-max-connections.cnf
      - ./container-volume/mc-observability/maria/mysql/conf.d:/etc/mysql/conf.d:ro
      - ./container-volume/mc-observability/maria/mysql:/var/lib/mysql
      - ./container-volume/mc-observability/maria/log:/var/log/maria
    environment:
      - TZ="Asia/Seoul"
      - ALLOW_EMPTY_PASSWORD=yes
      - MYSQL_ROOT_PASSWORD=qwe1212!Q
      - MYSQL_USER=mc-agent
      - MYSQL_DATABASE=mc_observability
      - MYSQL_PASSWORD=mc-agent
    networks:
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "healthcheck.sh", "--connect" ]
      <<: *default-health-check

  mc-observability-influx:
    image: influxdb:1.8
    container_name: mc-observability-influx
    ports:
      - target: 8086
        published: 8086
        protocol: tcp
      - target: 8082
        published: 8082
        protocol: tcp
    environment:
      - INFLUXDB_USER=mc-agent
      - INFLUXDB_PASSWORD=mc-agent
      - INFLUXDB_DB="mc-observability"
    volumes:
      - ./conf/mc-observability/influxdb/influxdb_init:/docker-entrypoint-initdb.d
      - ./container-volume/mc-observability/influxdb/config:/etc/influxdb
      - ./container-volume/mc-observability/influxdb:/root/.influxdb
    networks:
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8086/health" ]
      <<: *default-health-check

  mc-observability-chronograf:
    image: chronograf:1.9.4
    container_name: mc-observability-chronograf
    ports:
      - target: 8888
        published: 8888
        protocol: tcp
    volumes:
      - ./container-volume/mc-observability/chronograf/chronograf_data:/var/lib/chronograf
    networks:
      - mc-web-console-network
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8888/chronograf/v1/health" ]
      <<: *default-health-check

  mc-observability-kapacitor-init-volumes:
    image: busybox:stable
    container_name: mc-observability-kapacitor-init-volumes
    command: [ "sh", "-c", "chown -R 999:999 /var/lib/kapacitor" ]
    volumes:
      - ./container-volume/mc-observability/kapacitor:/var/lib/kapacitor
    user: root
    init: true
    networks:
      - mc-observability-network

  mc-observability-kapacitor:
    image: kapacitor:1.7.5
    container_name: mc-observability-kapacitor
    ports:
      - target: 9092
        published: 9092
        protocol: tcp
    environment:
      - KAPACITOR_INFLUXDB_0_URLS_0=http://mc-observability-influx:8086
    volumes:
      - ./container-volume/mc-observability/kapacitor:/var/lib/kapacitor
    networks:
      - mc-observability-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9092/kapacitor/v1/ping" ]
      <<: *default-health-check

  mc-observability-opensearch-init-volumes:
    image: busybox:stable
    container_name: mc-observability-opensearch-init-volumes
    command: [ "sh", "-c", "chown -R 1000:1000 /usr/share/opensearch/data" ]
    volumes:
      - ./container-volume/mc-observability/opensearch:/usr/share/opensearch/data
    user: root
    init: true
    networks:
      - mc-observability-network

  opensearch-node1:
    image: opensearchproject/opensearch:1.3.19
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node1
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
      - "DISABLE_SECURITY_PLUGIN=true"
      - "discovery.type=single-node"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - ./container-volume/mc-observability/opensearch:/usr/share/opensearch/data
    ports:
      - target: 9200
        published: 9200
        protocol: tcp
      - target: 9600
        published: 9600
        protocol: tcp
    networks:
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9200/_cluster/health" ]
      <<: *default-health-check

  mc-observability-opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:1.3.19
    container_name: mc-observability-opensearch-dashboards
    ports:
      - target: 5601
        published: 5601
        protocol: tcp
    environment:
      - 'OPENSEARCH_HOSTS=["http://opensearch-node1:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true"
    networks:
      - mc-web-console-network
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5601/api/status" ]
      <<: *default-health-check

  mc-observability-insight:
    image: cloudbaristaorg/mc-o11y-insight:0.4.0
    container_name: mc-observability-insight
    ports:
      - target: 9001
        published: 9001
        protocol: tcp
    environment:
      - TZ=Asia/Seoul
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-}
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - ./container-volume/mc-observability/insight/log:/mc-insight/log
    networks:
      - mc-observability-network
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:9001/docs" ]
      <<: *default-health-check

  mc-observability-insight-scheduler:
    image: cloudbaristaorg/mc-o11y-insight-scheduler:0.4.0
    container_name: mc-observability-insight-scheduler
    ports:
      - target: 9002
        published: 9002
        protocol: tcp
    depends_on:
      mc-observability-maria:
        condition: service_started
    environment:
      - TZ=Asia/Seoul
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=mysql+mysqldb://mc-agent:mc-agent@mc-observability-maria:3306/mc_airflow
      - AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true
    networks:
      - mc-observability-network
    volumes:
      - ./tool/mcc:/app/tool/mcc
      - /etc/localtime:/etc/localtime:ro
      - ./container-volume/mc-observability/scheduler/logs:/usr/local/airflow/logs
    command: >
      /bin/bash -c "
        # Wait for MySQL
        sleep 10

        # Clean up pid
        rm -f airflow-webserver.pid

        # Set up metadata database
        airflow db init

        # Create default user
        airflow users create --username admin --password admin --email admin@test.com --firstname admin --lastname admin --role Admin

        # Import variables & Make connections
        # airflow variables import -a overwrite /usr/local/airflow/airflow_variables.json
        airflow variables set --description 'O11Y Manger API BASE URL' API_BASE_URL http://mc-observability-manager:18080/api/o11y

        airflow connections add --conn-type http --conn-host mc-observability-insight --conn-schema http --conn-port 9001 api_base_url
        airflow connections add --conn-type mysql --conn-host mc-observability-maria --conn-schema mc_observability --conn-login mc-agent --conn-password mc-agent --conn-port 3306 mcmp_db
        airflow connections add --conn-type http --conn-host mc-observability-manager --conn-port 18080 o11y-manager
        airflow connections add --conn-type influxdb --conn-host mc-observability-influx --conn-port 8086 --conn-schema downsampling --conn-login mc-agent --conn-password mc-agent influxdb

        # Reload & Run dags
        airflow dags reserialize
        airflow dags unpause anomaly_detection
        airflow dags unpause down_sampling

        # Start airflow
        airflow scheduler & airflow webserver -p 9002

        # Keep the server on no matter what
        sleep infinity
            "
    healthcheck:
      test: [ "CMD", "/app/tool/mcc", "rest", "get", "http://localhost:8974/health" ]
      <<: *default-health-check

  mc-observability-mcp-grafana:
    image: mcp/grafana:latest
    container_name: mc-observability-mcp-grafana
    tty: true
    stdin_open: true
    ports:
      - target: 8000
        published: 8000
        protocol: tcp
    environment:
      - GRAFANA_URL=${GRAFANA_URL:-}
      - GRAFANA_API_KEY=${GRAFANA_API_KEY:-}
    command:
      - "--disable-sift"
      - "--disable-incident"
      - "--disable-search"
    networks:
      - mc-observability-network
